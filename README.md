# SAHYA  ü§ñ
<!---![Sahya](sahya.jpg)--->
*Here you can find various modules (coded in python) used to build SAHYA*

## Face Recognition ü§ñ
Using the [*face_recognition*](https://pypi.org/project/face_recognition/) library Sahya is able to finely recognize the people present in her dataset and greet them using [*text_to_speech*](https://pythonprogramminglanguage.com/text-to-speech/) module. 
#### Pre-Requisites
- [*face_recognition*](https://pypi.org/project/face_recognition/)
- [*cv2*](https://pypi.org/project/opencv-python/)
- *os* <br/>
make sure you have the specified libraries installed to run the text_to_speech module which is mentioned in the `speech` folder.

## Object Detection ü§ñ
Using the [YOLO](https://towardsdatascience.com/yolo-you-only-look-once-real-time-object-detection-explained-492dc9230006) algorithm,(You only look once) which is an object detection system targeted for real-time processing, Sahya is able to detect objects using the pre-trained data.
#### Pre-Requisites
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*kindly look into the* `setup.md` *file for running the code smoothly*

## Speech ü§ñ
This folder consists of python codes to perform `Text_to_Speech` and `Speech_to_Text` operations.
#### Pre-Requisites
Text to Speech : <br/>
- [*gTTS*](https://pypi.org/project/gTTS/)
- [*pyglet*](https://pypi.org/project/pyglet/)
- *os*

Speech to Text : <br/>
- [*SpeechRecognition*](https://pypi.org/project/SpeechRecognition/)

## Perspective Viewing ü§ñ
This code divides the live streaming into three different screens which shows the the Left, Center and Right perspective views.
#### Pre-Requisites
- [*cv2*](https://pypi.org/project/opencv-python/)
- [*numpy*](https://www.numpy.org/)

---------------------------------------------------------------------------------------------------------------------------------

`Hearty thanks to all the coders and developers for their knowledge, help and support` 




*made with* :heart: 
üë©üèª‚Äçüíª üë®üèΩ‚Äçüíª
